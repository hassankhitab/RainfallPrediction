# -*- coding: utf-8 -*-
"""Final Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18m4IikqefMt5hdPnddu8u-UzBWoGLlJg
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, jaccard_score, f1_score, log_loss, mean_absolute_error, mean_squared_error, r2_score
import os
from datetime import datetime

print("Current working directory:", os.getcwd())

# Read the CSV file
data = pd.read_csv('/content/weatherAUS.csv')

# Print the column names
print("Column names:", data.columns)
import matplotlib.pyplot as plt
import seaborn as sns


plt.figure(figsize = (8,8))
sns.scatterplot(x = 'MaxTemp', y = 'MinTemp', hue = 'RainTomorrow' , palette = 'inferno',data = data)
# Data cleaning and preprocessing
# Convert 'Date' column to datetime object
data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')

# Extract year, month, and day as separate features
data['Year'] = data['Date'].dt.year
data['Month'] = data['Date'].dt.month
data['Day'] = data['Date'].dt.day

# Drop the original 'Date' column
data.drop('Date', axis=1, inplace=True)

# Handle missing values
# Fill missing values for numeric columns with the median
numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())

# Fill missing values for categorical columns with the most frequent value
categorical_cols = data.select_dtypes(include=['object']).columns
data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])

# Convert categorical columns to numerical values
data = pd.get_dummies(data, drop_first=True)

# Define features and target
X = data.drop('RainTomorrow_Yes', axis=1)  # Ensure the target column is correctly named after encoding
y = data['RainTomorrow_Yes']  # Ensure the target column is correctly named after encoding

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model building and evaluation
models = {
    "Linear Regression": LinearRegression(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Logistic Regression": LogisticRegression()

}

for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    if model_name == "Linear Regression":
        print(f"Model: {model_name}")
        print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.3f}")
        print(f"Mean Squared Error: {mean_squared_error(y_test, y_pred):.3f}")
        print(f"R2-Score: {r2_score(y_test, y_pred):.3f}")
    else:
        print(f"Model: {model_name}")
        print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")
        print(f"Jaccard Index: {jaccard_score(y_test, y_pred):.3f}")
        print(f"F1-Score: {f1_score(y_test, y_pred):.3f}")
        print(f"LogLoss: {log_loss(y_test, y_pred):.3f}")
    print()

import matplotlib.pyplot as plt
import seaborn as sns


plt.figure(figsize = (8,8))
sns.scatterplot(x = 'MaxTemp', y = 'MinTemp', hue = 'RainTomorrow' , palette = 'inferno',data = data)

